{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UrbanSound8K metadata\n",
    "- I write this notebook to learn how to handle audio dataset. \n",
    "- What I refered(almost copied): [Link](https://github.com/keunwoochoi/UrbanSound8K-preprocessing/blob/master/preprocess_urban.ipynb)\n",
    "- It creates three files, train, valid, and test + .h5\n",
    "- Split: folder 1-8: train, 9:valid, 10:test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "SRC_ROOT = \"UrbanSound8K\"\n",
    "HDF_PATH = \"urbansound8k_hdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(SRC_ROOT + \"/metadata/UrbanSound8K.csv\")\n",
    "class_ids = sorted(metadata['classID'].unique())\n",
    "fold_ids = sorted(metadata['fold'].unique())\n",
    "print(\"class id list: {}\".format(class_ids))\n",
    "print(\"fold id list: {}\".format(fold_ids))\n",
    "\n",
    "# Sort metadata by class id\n",
    "metadata.sort_values(by=[\"classID\"], inplace=True)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of data: {}\".format(metadata.shape[0]))\n",
    "print(\"Number of classes: {}\".format(metadata['class'].nunique()))\n",
    "print(\"Classes: {}\".format(metadata['class'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize decription list\n",
    "data_description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_num in fold_ids:\n",
    "    data_description.append(\n",
    "        metadata[metadata.fold == fold_num]['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = pd.DataFrame(data_description)\n",
    "data_description['folder'] = [\"fold\" + str(x) for x in fold_ids]\n",
    "data_description.set_index('folder', inplace = True)\n",
    "data_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fold9 will be **validation set** and fold10 will be **test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling\n",
    "- The shuffling should be WITHIN each dataset\n",
    "    - For example, train data should be shuffled in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(SRC_ROOT + \"/metadata/UrbanSound8K.csv\", header=0)\n",
    "N_TRAIN = len(df[df['fold']<9])\n",
    "N_VALID = len(df[df['fold']==9])\n",
    "N_TEST = len(df[df['fold']==10])\n",
    "print(\"Number of Train data: {}\".format(N_TRAIN))\n",
    "print(\"Number of Valid data: {}\".format(N_VALID))\n",
    "print(\"Number of Test data: {}\".format(N_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('shuffled_idxs.npy'):\n",
    "    np.random.seed(42)  # for reproducibility\n",
    "    train_shfl_idxs = np.random.permutation(N_TRAIN)\n",
    "    valid_shfl_idxs = np.random.permutation(N_VALID)\n",
    "    test_shfl_idxs = np.random.permutation(N_TEST)\n",
    "    np.save(\"shuffled_idxs.npy\", [train_shfl_idxs, valid_shfl_idxs, test_shfl_idxs])\n",
    "    print(\"Generated new shuffled index file\")\n",
    "    \n",
    "[train_shfl_idxs, valid_shfl_idxs, test_shfl_idxs] = np.load(\n",
    "    'shuffled_idxs.npy', allow_pickle=True)\n",
    "print(\"Shuffle index loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw audio saving config\n",
    "\n",
    "# Sample rate in Hz\n",
    "SAMPLE_RATE = 44100 \n",
    "\n",
    "# should be < 4.0. Not recommend to change. \n",
    "MAX_LEN_SEC = 4.0 \n",
    "\n",
    "LEN_RAW = int(SAMPLE_RATE * MAX_LEN_SEC)\n",
    "\n",
    "CLASS_COUNT = len(metadata['classID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_label(row_index, row, dataset):\n",
    "    class_id = getattr(row, 'classID')\n",
    "    \n",
    "    # One-hot encoding\n",
    "    dataset[row_index, class_id] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_raw(row_index, row, dataset):\n",
    "    fname, fold = getattr(row, 'slice_file_name'), getattr(row, 'fold') \n",
    "    src_path = SRC_ROOT + \"/audio/fold\" + str(fold) + '/' + fname\n",
    "    src, sr = librosa.load(src_path, SAMPLE_RATE)\n",
    "    dataset[row_index, :min(LEN_RAW, len(src))] = src[:LEN_RAW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_urban_sound_8k_hdf(hdf_file_path, dataframe_subset, shuffle_index):\n",
    "    start_time = time.time()\n",
    "    num_data = len(dataframe_subset)\n",
    "    with h5py.File(hdf_file_path, 'w') as f_hdf:\n",
    "        ds_raw_data = f_hdf.create_dataset('raw', (num_data, LEN_RAW), dtype='float32')\n",
    "        ds_label = f_hdf.create_dataset('label', (num_data, CLASS_COUNT), dtype='float32')\n",
    "        for row_index, row in enumerate(dataframe_subset.iloc[shuffle_index].itertuples()):\n",
    "            row_to_raw(row_index, row, ds_raw_data)\n",
    "            row_to_label(row_index, row, ds_label)\n",
    "            if row_index % 100 == 0:\n",
    "                sys.stdout.write(\"\\r{0}/{1}-th sample was written\".format(row_index + 1, num_data))\n",
    "        print(\"The file {0} save done: It took {1} seconds.\".format(\n",
    "            hdf_file_path ,int(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training sets\n",
    "save_urban_sound_8k_hdf(HDF_PATH+'train.h5', df[df['fold']<9], train_shfl_idxs)\n",
    "save_urban_sound_8k_hdf(HDF_PATH+'validate.h5', df[df['fold']==9], valid_shfl_idxs)\n",
    "save_urban_sound_8k_hdf(HDF_PATH+'test.h5', df[df['fold']==10], test_shfl_idxs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
